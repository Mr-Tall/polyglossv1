{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b720a8f9-a47b-4a1f-bdf1-432beaf77a81",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'custom_tokenizers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mst_data\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IGTLine\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data_file\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124;03m\"\"\"Loads a file containing IGT data into a list of entries.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Research/glosslm/st_data/data.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01menum\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Enum\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcustom_tokenizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mencoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_vocab, MultiVocabularyEncoder\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mModelType\u001b[39;00m(Enum):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'custom_tokenizers'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from st_data.data import IGTLine\n",
    "\n",
    "def load_data_file(path: str):\n",
    "    \"\"\"Loads a file containing IGT data into a list of entries.\"\"\"\n",
    "    all_data = []\n",
    "\n",
    "    # If we have a directory, recursively load all files and concat together\n",
    "    if os.path.isdir(path):\n",
    "        for file in os.listdir(path):\n",
    "            if file.endswith(\".txt\"):\n",
    "                all_data.extend(load_data_file(os.path.join(path, file)))\n",
    "        return all_data\n",
    "\n",
    "    # If we have one file, read in line by line\n",
    "    with open(path, 'r') as file:\n",
    "        current_entry = [None, None, None, None]  # transc, segm, gloss, transl\n",
    "\n",
    "        for line in file:\n",
    "            # Determine the type of line\n",
    "            # If we see a type that has already been filled for the current entry, something is wrong\n",
    "            line_prefix = line[:2]\n",
    "            if line_prefix == '\\\\t' and current_entry[0] == None:\n",
    "                current_entry[0] = line[3:].strip()\n",
    "            elif line_prefix == '\\\\m' and current_entry[1] == None:\n",
    "                current_entry[1] = line[3:].strip()\n",
    "            elif line_prefix == '\\\\p' and current_entry[2] == None:\n",
    "                if len(line[3:].strip()) > 0:\n",
    "                    current_entry[2] = line[3:].strip()\n",
    "            elif line_prefix == '\\\\l' and current_entry[3] == None:\n",
    "                current_entry[3] = line[3:].strip()\n",
    "                # Once we have the translation, we've reached the end and can save this entry\n",
    "                all_data.append(IGTLine(transcription=current_entry[0],\n",
    "                                        segmentation=current_entry[1],\n",
    "                                        glosses=current_entry[2],\n",
    "                                        translation=current_entry[3]))\n",
    "                current_entry = [None, None, None, None]\n",
    "            elif line.strip() != \"\":\n",
    "                # Something went wrong\n",
    "                continue\n",
    "            else:\n",
    "                if not current_entry == [None, None, None, None]:\n",
    "                    all_data.append(IGTLine(transcription=current_entry[0],\n",
    "                                            segmentation=current_entry[1],\n",
    "                                            glosses=current_entry[2],\n",
    "                                            translation=None))\n",
    "                    current_entry = [None, None, None, None]\n",
    "        # Might have one extra line at the end\n",
    "        if not current_entry == [None, None, None, None]:\n",
    "            all_data.append({\"transcr\"})\n",
    "            all_data.append(IGTLine(transcription=current_entry[0],\n",
    "                                    segmentation=current_entry[1],\n",
    "                                    glosses=current_entry[2],\n",
    "                                    translation=None))\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e0eee2-4c09-48df-834f-b99e85e8dd92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arp = load_data_file(\"./st_data/Arapaho/st_data/arp-CLDFmaster.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86ca3e0-cd23-45af-af01-63b55a4720a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
